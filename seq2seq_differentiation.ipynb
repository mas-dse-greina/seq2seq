{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence prediction\n",
    "\n",
    "We'll create a seq2seq LSTM model in Keras which will predict one sequence based on another. In this case, the input sequence is a random permutation of numbers from 1 to 9. The output sequence is the difference between every successive value in the input sequence (with 0 to pad the output sequence at the start)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_timesteps_in = 8   # Number of values in the input sequence\n",
    "n_timesteps_out = 8  # Number of values in the output sequence \n",
    "\n",
    "n_hidden_units = 200   # Number of hidden units in the LSTM\n",
    "\n",
    "int_low = 1   # Minimum value possible in a legal input sequence\n",
    "int_high = 9   # Maxmum value possible in a legal input sequence\n",
    "pad_value = -9999   # Value of pad (end of the sequence)\n",
    "unknown_value = 9999  # Value of anything not in the expected vocabulary\n",
    "\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/anaconda3/envs/tf/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_values = np.arange(int_low,int_high+1,1)\n",
    "all_values = np.append(np.insert(legal_values, 0, pad_value), unknown_value)\n",
    "combined_values = np.arange(int_high+1, int_high*2)\n",
    "\n",
    "# This won't predict -18 and +18. So they'll be our unknown values\n",
    "all_values = np.append(all_values, combined_values)\n",
    "all_values = np.append(all_values, -combined_values)\n",
    "n_features = len(all_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sequence(length):\n",
    "    return np.random.permutation(legal_values)[:length]\n",
    "\n",
    "def one_hot_encode(sequence):\n",
    "    encoding = []\n",
    "    for value in sequence:\n",
    "        vector = np.zeros_like(all_values)\n",
    "        if value in all_values:\n",
    "            vector[np.where(all_values==value)[0]] = 1\n",
    "        else:\n",
    "            vector[np.where(all_values==unknown_value)[0]] = 1\n",
    "        encoding.append(vector)\n",
    "        \n",
    "    encoding = np.array(encoding)\n",
    "    encoding = encoding.reshape(1, encoding.shape[0], encoding.shape[1])\n",
    "    return np.array(encoding)\n",
    "\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [all_values[np.argmax(vector)] for vector in encoded_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_in = generate_sequence(8)\n",
    "sequence_transform = np.insert(np.diff(sequence_in), 0, 0)\n",
    "sequence_out = np.ones_like(sequence_in)*pad_value\n",
    "sequence_out[:8] = sequence_transform[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pair(n_in, n_out):\n",
    "    # generate random sequence from possible values\n",
    "    sequence_in = generate_sequence(n_in)\n",
    "    sequence_transform = np.insert(np.diff(sequence_in), 0, 0)\n",
    "    sequence_out = np.ones_like(sequence_in)*pad_value\n",
    "    sequence_out[:n_out] = sequence_transform[:n_out]\n",
    "    \n",
    "    # One Hot Encode the input values\n",
    "    X = one_hot_encode(sequence_in)\n",
    "    y = one_hot_encode(sequence_out)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(n_in, n_out, batch_size):\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        for idx in range(batch_size):\n",
    "            \n",
    "            X,y = get_pair(n_in, n_out)\n",
    "            X_batch.append(X[0])\n",
    "            y_batch.append(y[0])\n",
    "            \n",
    "        yield np.array(X_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden_units, input_shape=(n_timesteps_in, n_features)))\n",
    "model.add(RepeatVector(n_timesteps_in))\n",
    "model.add(LSTM(n_hidden_units, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_features, activation=\"softmax\")))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " - 81s - loss: 2.8934 - acc: 0.1738 - val_loss: 2.7325 - val_acc: 0.1835\n",
      "Epoch 2/15\n",
      " - 76s - loss: 2.5357 - acc: 0.2037 - val_loss: 2.3190 - val_acc: 0.2324\n",
      "Epoch 3/15\n",
      " - 71s - loss: 1.9871 - acc: 0.3192 - val_loss: 1.5351 - val_acc: 0.4506\n",
      "Epoch 4/15\n",
      " - 71s - loss: 1.1586 - acc: 0.5737 - val_loss: 0.8839 - val_acc: 0.6603\n",
      "Epoch 5/15\n",
      " - 71s - loss: 0.6639 - acc: 0.7655 - val_loss: 0.5222 - val_acc: 0.8196\n",
      "Epoch 6/15\n",
      " - 71s - loss: 0.4263 - acc: 0.8629 - val_loss: 0.3134 - val_acc: 0.9180\n",
      "Epoch 7/15\n",
      " - 72s - loss: 0.2863 - acc: 0.9159 - val_loss: 0.2064 - val_acc: 0.9479\n",
      "Epoch 8/15\n",
      " - 72s - loss: 0.1972 - acc: 0.9451 - val_loss: 0.1096 - val_acc: 0.9840\n",
      "Epoch 9/15\n",
      " - 72s - loss: 0.1394 - acc: 0.9624 - val_loss: 0.0604 - val_acc: 0.9940\n",
      "Epoch 10/15\n",
      " - 72s - loss: 0.1049 - acc: 0.9718 - val_loss: 0.0394 - val_acc: 0.9967\n",
      "Epoch 11/15\n",
      " - 74s - loss: 0.0828 - acc: 0.9777 - val_loss: 0.0252 - val_acc: 0.9983\n",
      "Epoch 12/15\n",
      " - 72s - loss: 0.0681 - acc: 0.9817 - val_loss: 0.0182 - val_acc: 0.9987\n",
      "Epoch 13/15\n",
      " - 75s - loss: 0.0576 - acc: 0.9847 - val_loss: 0.0132 - val_acc: 0.9992\n",
      "Epoch 14/15\n",
      " - 73s - loss: 0.0517 - acc: 0.9861 - val_loss: 0.2833 - val_acc: 0.8959\n",
      "Epoch 15/15\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "training_steps = 1000\n",
    "validation_steps = 100\n",
    "\n",
    "train_generator = get_batch(n_timesteps_in, n_timesteps_out, batch_size)\n",
    "validate_generator = get_batch(n_timesteps_in, n_timesteps_out, batch_size)\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=training_steps, epochs=num_epochs, \n",
    "                              validation_data=validate_generator, validation_steps=validation_steps,\n",
    "                              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a few example predictions to sanity check trained model\n",
    "num_examples=10\n",
    "for idx in range(num_examples):\n",
    "    X,y = get_pair(n_timesteps_in, n_timesteps_out)\n",
    "    yhat = model.predict(X, verbose=0)\n",
    "    print(\"*\"*20)\n",
    "    print(\"Test case #{}\".format(idx+1))\n",
    "    print(\"Input = \", one_hot_decode(X[0]))\n",
    "    print(\"Expected Output:\", one_hot_decode(y[0]))\n",
    "    print(\"Model Predicted Output:\", one_hot_decode(yhat[0]))\n",
    "    print(\"*\"*20)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = one_hot_encode([3,2, 4,5,-3,2,1,4])\n",
    "yhat = model.predict(X, verbose=0)\n",
    "print(\"*\"*20)\n",
    "print(\"Manual Test Case\".format(idx+1))\n",
    "print(\"Input = \", one_hot_decode(X[0]))\n",
    "print(\"Expected Output:\", one_hot_decode(y[0]))\n",
    "print(\"Model Predicted Output:\", one_hot_decode(yhat[0]))\n",
    "print(\"*\"*20)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
